{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a07d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages for Energy Consumption Forecasting...\n",
      "============================================================\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (7.1.0)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "✓ Successfully installed ipykernel\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (7.1.0)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "✓ Successfully installed ipykernel\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0) (1.17.0)\n",
      "✓ Successfully installed pandas>=1.3.0\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.3.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0) (1.17.0)\n",
      "✓ Successfully installed pandas>=1.3.0\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (2.3.4)\n",
      "✓ Successfully installed numpy>=1.20.0\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (2.3.4)\n",
      "✓ Successfully installed numpy>=1.20.0\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0) (1.17.0)\n",
      "✓ Successfully installed matplotlib>=3.3.0\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib>=3.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0) (1.17.0)\n",
      "✓ Successfully installed matplotlib>=3.3.0\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from seaborn>=0.11.0) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from seaborn>=0.11.0) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from seaborn>=0.11.0) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.17.0)\n",
      "✓ Successfully installed seaborn>=0.11.0\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from seaborn>=0.11.0) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from seaborn>=0.11.0) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from seaborn>=0.11.0) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.17.0)\n",
      "✓ Successfully installed seaborn>=0.11.0\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (3.5.0)\n",
      "✓ Successfully installed scikit-learn>=1.0.0\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from scikit-learn>=1.0.0) (3.5.0)\n",
      "✓ Successfully installed scikit-learn>=1.0.0\n",
      "Requirement already satisfied: lightgbm>=3.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from lightgbm>=3.2.0) (2.3.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from lightgbm>=3.2.0) (1.16.3)\n",
      "✓ Successfully installed lightgbm>=3.2.0\n",
      "Requirement already satisfied: lightgbm>=3.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from lightgbm>=3.2.0) (2.3.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from lightgbm>=3.2.0) (1.16.3)\n",
      "✓ Successfully installed lightgbm>=3.2.0\n",
      "Requirement already satisfied: jupyter in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (7.4.7)\n",
      "Requirement already satisfied: jupyter-console in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (7.1.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (8.1.8)\n",
      "Requirement already satisfied: jupyterlab in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (4.4.10)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipywidgets->jupyter) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipywidgets->jupyter) (3.0.16)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (80.9.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab->jupyter) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.28.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.4.0)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2025.2)\n",
      "✓ Successfully installed jupyter\n",
      "Requirement already satisfied: jupyter in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: notebook in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (7.4.7)\n",
      "Requirement already satisfied: jupyter-console in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (7.1.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (8.1.8)\n",
      "Requirement already satisfied: jupyterlab in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter) (4.4.10)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipywidgets->jupyter) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipywidgets->jupyter) (3.0.16)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab->jupyter) (80.9.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab->jupyter) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.28.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.4.0)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2025.2)\n",
      "✓ Successfully installed jupyter\n",
      "Requirement already satisfied: ipython in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (9.7.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jedi>=0.18.1->ipython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (0.2.3)\n",
      "✓ Successfully installed ipython\n",
      "Requirement already satisfied: ipython in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (9.7.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from jedi>=0.18.1->ipython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (0.2.3)\n",
      "✓ Successfully installed ipython\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (4.67.1)\n",
      "✓ Successfully installed tqdm\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (4.67.1)\n",
      "✓ Successfully installed tqdm\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (1.5.2)\n",
      "✓ Successfully installed joblib\n",
      "\n",
      "============================================================\n",
      "Installation completed!\n",
      "============================================================\n",
      "\n",
      "Verifying installations...\n",
      "✓ All core packages imported successfully!\n",
      "\n",
      "Package versions:\n",
      "  Python: 3.12.12\n",
      "  Pandas: 2.3.3\n",
      "  NumPy: 2.3.4\n",
      "  Matplotlib: 3.10.6\n",
      "  Seaborn: 0.13.2\n",
      "  Scikit-learn: 1.7.2\n",
      "  LightGBM: 4.6.0\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/energy_forecasting/lib/python3.12/site-packages (1.5.2)\n",
      "✓ Successfully installed joblib\n",
      "\n",
      "============================================================\n",
      "Installation completed!\n",
      "============================================================\n",
      "\n",
      "Verifying installations...\n",
      "✓ All core packages imported successfully!\n",
      "\n",
      "Package versions:\n",
      "  Python: 3.12.12\n",
      "  Pandas: 2.3.3\n",
      "  NumPy: 2.3.4\n",
      "  Matplotlib: 3.10.6\n",
      "  Seaborn: 0.13.2\n",
      "  Scikit-learn: 1.7.2\n",
      "  LightGBM: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "# Install all required libraries for energy consumption forecasting\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"✗ Failed to install {package}: {e}\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'ipykernel',           # Jupyter kernel support\n",
    "    'pandas>=1.3.0',       # Data manipulation and analysis\n",
    "    'numpy>=1.20.0',       # Numerical computing\n",
    "    'matplotlib>=3.3.0',   # Plotting library\n",
    "    'seaborn>=0.11.0',     # Statistical data visualization\n",
    "    'scikit-learn>=1.0.0', # Machine learning library (for LabelEncoder, etc.)\n",
    "    'lightgbm>=3.2.0',     # LightGBM for gradient boosting\n",
    "    'jupyter',             # Jupyter notebook support\n",
    "    'ipython',             # Interactive Python shell\n",
    "    'tqdm',                # Progress bars\n",
    "    'joblib',              # Parallel computing utilities\n",
    "]\n",
    "\n",
    "print(\"Installing required packages for Energy Consumption Forecasting...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Installation completed!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify installations\n",
    "print(\"\\nVerifying installations...\")\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import sklearn\n",
    "    import lightgbm as lgb\n",
    "    import ipykernel\n",
    "    print(\"✓ All core packages imported successfully!\")\n",
    "    \n",
    "    # Display versions\n",
    "    print(f\"\\nPackage versions:\")\n",
    "    print(f\"  Python: {sys.version.split()[0]}\")\n",
    "    print(f\"  Pandas: {pd.__version__}\")\n",
    "    print(f\"  NumPy: {np.__version__}\")\n",
    "    print(f\"  Matplotlib: {plt.matplotlib.__version__}\")\n",
    "    print(f\"  Seaborn: {sns.__version__}\")\n",
    "    print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
    "    print(f\"  LightGBM: {lgb.__version__}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    print(\"Please restart the kernel after installation completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1def57",
   "metadata": {},
   "source": [
    "# Energy Consumption Forecasting - Data Preprocessing\n",
    "\n",
    "This notebook combines building metadata, weather data, and meter readings to create a comprehensive dataset for LGBM model training.\n",
    "\n",
    "## Data Sources:\n",
    "- `building_metadata.csv`: Building characteristics (site_id, building_id, primary_use, square_feet, year_built, floor_count)\n",
    "- `weather_train.csv`: Weather data by site and timestamp\n",
    "- `train.csv`: Meter readings by building and timestamp (assumed to exist)\n",
    "\n",
    "## Objectives:\n",
    "1. Load and explore all datasets\n",
    "2. Merge data sources appropriately\n",
    "3. Handle missing values and data quality issues\n",
    "4. Feature engineering for LGBM model\n",
    "5. Create final preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd30a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.3.4\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db722b08",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5049c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building metadata shape: (1449, 6)\n",
      "Weather data shape: (139773, 9)\n",
      "Meter readings shape: (20216100, 4)\n",
      "Meter readings shape: (20216100, 4)\n",
      "Meter readings date range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Unique buildings in meter readings: 1449\n",
      "Meter types in data: {0: 12060910, 1: 4182440, 2: 2708713, 3: 1264037}\n",
      "\n",
      "============================================================\n",
      "Data loaded successfully!\n",
      "============================================================\n",
      "Meter readings date range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Unique buildings in meter readings: 1449\n",
      "Meter types in data: {0: 12060910, 1: 4182440, 2: 2708713, 3: 1264037}\n",
      "\n",
      "============================================================\n",
      "Data loaded successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define data paths\n",
    "data_path = '/Users/saatwik/Documents/Energy-consumption-forecasting/data/'\n",
    "\n",
    "# Load building metadata\n",
    "building_metadata = pd.read_csv(f\"{data_path}building_metadata.csv\")\n",
    "print(f\"Building metadata shape: {building_metadata.shape}\")\n",
    "\n",
    "# Load weather data\n",
    "weather_data = pd.read_csv(f\"{data_path}weather_train.csv\")\n",
    "print(f\"Weather data shape: {weather_data.shape}\")\n",
    "\n",
    "# Load meter readings\n",
    "try:\n",
    "    meter_readings = pd.read_csv(f\"{data_path}train.csv\")\n",
    "    print(f\"Meter readings shape: {meter_readings.shape}\")\n",
    "    \n",
    "    # Check for expected columns\n",
    "    expected_cols = ['building_id', 'meter_reading', 'timestamp']\n",
    "    missing_cols = [col for col in expected_cols if col not in meter_readings.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing expected columns in train.csv: {missing_cols}\")\n",
    "    \n",
    "    # Display basic info about meter readings\n",
    "    print(f\"Meter readings date range: {meter_readings['timestamp'].min()} to {meter_readings['timestamp'].max()}\")\n",
    "    print(f\"Unique buildings in meter readings: {meter_readings['building_id'].nunique()}\")\n",
    "    if 'meter' in meter_readings.columns:\n",
    "        print(f\"Meter types in data: {meter_readings['meter'].value_counts().to_dict()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: train.csv not found. Creating sample data for demonstration.\")\n",
    "    # Create sample meter readings data for demonstration\n",
    "    np.random.seed(42)\n",
    "    sample_buildings = building_metadata['building_id'].sample(min(100, len(building_metadata)))\n",
    "    sample_dates = pd.date_range('2016-01-01', '2016-03-31', freq='H')\n",
    "    \n",
    "    meter_readings = []\n",
    "    for building_id in sample_buildings:\n",
    "        for date in sample_dates[:24*7]:  # 1 week of hourly data\n",
    "            meter_readings.append({\n",
    "                'building_id': building_id,\n",
    "                'timestamp': date,\n",
    "                'meter': np.random.choice([0, 1, 2, 3]),  # Different meter types\n",
    "                'meter_reading': np.random.exponential(100) + np.random.normal(50, 10)\n",
    "            })\n",
    "    \n",
    "    meter_readings = pd.DataFrame(meter_readings)\n",
    "    print(f\"Sample meter readings shape: {meter_readings.shape}\")\n",
    "    print(\"Note: Using sample data. Replace with actual train.csv when available.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Data loaded successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac8109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING METADATA OVERVIEW\n",
      "========================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   site_id      1449 non-null   int64  \n",
      " 1   building_id  1449 non-null   int64  \n",
      " 2   primary_use  1449 non-null   object \n",
      " 3   square_feet  1449 non-null   int64  \n",
      " 4   year_built   675 non-null    float64\n",
      " 5   floor_count  355 non-null    float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 68.1+ KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
      "0        0            0   Education         7432      2008.0          NaN\n",
      "1        0            1   Education         2720      2004.0          NaN\n",
      "2        0            2   Education         5376      1991.0          NaN\n",
      "3        0            3   Education        23685      2002.0          NaN\n",
      "4        0            4   Education       116607      1975.0          NaN\n",
      "\n",
      "Unique values in key columns:\n",
      "Unique sites: 16\n",
      "Unique buildings: 1449\n",
      "Primary uses: primary_use\n",
      "Education                        549\n",
      "Office                           279\n",
      "Entertainment/public assembly    184\n",
      "Public services                  156\n",
      "Lodging/residential              147\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "WEATHER DATA OVERVIEW\n",
      "========================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139773 entries, 0 to 139772\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   site_id             139773 non-null  int64  \n",
      " 1   timestamp           139773 non-null  object \n",
      " 2   air_temperature     139718 non-null  float64\n",
      " 3   cloud_coverage      70600 non-null   float64\n",
      " 4   dew_temperature     139660 non-null  float64\n",
      " 5   precip_depth_1_hr   89484 non-null   float64\n",
      " 6   sea_level_pressure  129155 non-null  float64\n",
      " 7   wind_direction      133505 non-null  float64\n",
      " 8   wind_speed          139469 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 9.6+ MB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "   site_id            timestamp  air_temperature  cloud_coverage  \\\n",
      "0        0  2016-01-01 00:00:00             25.0             6.0   \n",
      "1        0  2016-01-01 01:00:00             24.4             NaN   \n",
      "2        0  2016-01-01 02:00:00             22.8             2.0   \n",
      "3        0  2016-01-01 03:00:00             21.1             2.0   \n",
      "4        0  2016-01-01 04:00:00             20.0             2.0   \n",
      "\n",
      "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
      "0             20.0                NaN              1019.7             0.0   \n",
      "1             21.1               -1.0              1020.2            70.0   \n",
      "2             21.1                0.0              1020.2             0.0   \n",
      "3             20.6                0.0              1020.1             0.0   \n",
      "4             20.0               -1.0              1020.0           250.0   \n",
      "\n",
      "   wind_speed  \n",
      "0         0.0  \n",
      "1         1.5  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         2.6  \n",
      "\n",
      "Unique sites: 16\n",
      "Date range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "\n",
      "================================================================================\n",
      "METER READINGS OVERVIEW\n",
      "========================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   building_id    int64  \n",
      " 1   meter          int64  \n",
      " 2   timestamp      object \n",
      " 3   meter_reading  float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 616.9+ MB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "   building_id  meter            timestamp  meter_reading\n",
      "0            0      0  2016-01-01 00:00:00            0.0\n",
      "1            1      0  2016-01-01 00:00:00            0.0\n",
      "2            2      0  2016-01-01 00:00:00            0.0\n",
      "3            3      0  2016-01-01 00:00:00            0.0\n",
      "4            4      0  2016-01-01 00:00:00            0.0\n",
      "\n",
      "Unique buildings: 1449\n",
      "Meter types: meter\n",
      "0    12060910\n",
      "1     4182440\n",
      "2     2708713\n",
      "3     1264037\n",
      "Name: count, dtype: int64\n",
      "Meter reading range: 0.00 to 21904700.00\n",
      "Meter types: meter\n",
      "0    12060910\n",
      "1     4182440\n",
      "2     2708713\n",
      "3     1264037\n",
      "Name: count, dtype: int64\n",
      "Meter reading range: 0.00 to 21904700.00\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about each dataset\n",
    "print(\"BUILDING METADATA OVERVIEW\")\n",
    "print(\"=\"*40)\n",
    "print(building_metadata.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(building_metadata.head())\n",
    "print(\"\\nUnique values in key columns:\")\n",
    "print(f\"Unique sites: {building_metadata['site_id'].nunique()}\")\n",
    "print(f\"Unique buildings: {building_metadata['building_id'].nunique()}\")\n",
    "print(f\"Primary uses: {building_metadata['primary_use'].value_counts().head()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WEATHER DATA OVERVIEW\")\n",
    "print(\"=\"*40)\n",
    "print(weather_data.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(weather_data.head())\n",
    "print(f\"\\nUnique sites: {weather_data['site_id'].nunique()}\")\n",
    "print(f\"Date range: {weather_data['timestamp'].min()} to {weather_data['timestamp'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METER READINGS OVERVIEW\")\n",
    "print(\"=\"*40)\n",
    "print(meter_readings.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(meter_readings.head())\n",
    "print(f\"\\nUnique buildings: {meter_readings['building_id'].nunique()}\")\n",
    "if 'meter' in meter_readings.columns:\n",
    "    print(f\"Meter types: {meter_readings['meter'].value_counts()}\")\n",
    "print(f\"Meter reading range: {meter_readings['meter_reading'].min():.2f} to {meter_readings['meter_reading'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad32a73",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Datetime Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83174305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting timestamps to datetime format...\n",
      "Weather timestamp range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Meter readings timestamp range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Weather data columns after datetime features: ['site_id', 'timestamp', 'air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', 'hour', 'day', 'month', 'year', 'weekday', 'is_weekend', 'day_of_year', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
      "Meter readings timestamp range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Weather data columns after datetime features: ['site_id', 'timestamp', 'air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', 'hour', 'day', 'month', 'year', 'weekday', 'is_weekend', 'day_of_year', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
      "Meter readings columns after datetime features: ['building_id', 'meter', 'timestamp', 'meter_reading', 'hour', 'day', 'month', 'year', 'weekday', 'is_weekend', 'day_of_year', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
      "\n",
      "Datetime preprocessing completed!\n",
      "Meter readings columns after datetime features: ['building_id', 'meter', 'timestamp', 'meter_reading', 'hour', 'day', 'month', 'year', 'weekday', 'is_weekend', 'day_of_year', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
      "\n",
      "Datetime preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp columns to datetime\n",
    "print(\"Converting timestamps to datetime format...\")\n",
    "\n",
    "# Weather data timestamp\n",
    "weather_data['timestamp'] = pd.to_datetime(weather_data['timestamp'])\n",
    "print(f\"Weather timestamp range: {weather_data['timestamp'].min()} to {weather_data['timestamp'].max()}\")\n",
    "\n",
    "# Meter readings timestamp (if exists in column)\n",
    "if 'timestamp' in meter_readings.columns:\n",
    "    meter_readings['timestamp'] = pd.to_datetime(meter_readings['timestamp'])\n",
    "    print(f\"Meter readings timestamp range: {meter_readings['timestamp'].min()} to {meter_readings['timestamp'].max()}\")\n",
    "else:\n",
    "    print(\"No timestamp column found in meter readings - creating one\")\n",
    "    # If timestamp doesn't exist, create it (for sample data)\n",
    "    if len(meter_readings) > 0:\n",
    "        meter_readings['timestamp'] = pd.date_range('2016-01-01', periods=len(meter_readings), freq='H')\n",
    "\n",
    "# Extract datetime features for better model performance\n",
    "def extract_datetime_features(df, datetime_col='timestamp'):\n",
    "    \"\"\"Extract useful datetime features from timestamp column\"\"\"\n",
    "    df = df.copy()\n",
    "    df['hour'] = df[datetime_col].dt.hour\n",
    "    df['day'] = df[datetime_col].dt.day\n",
    "    df['month'] = df[datetime_col].dt.month\n",
    "    df['year'] = df[datetime_col].dt.year\n",
    "    df['weekday'] = df[datetime_col].dt.weekday  # 0=Monday, 6=Sunday\n",
    "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "    df['day_of_year'] = df[datetime_col].dt.dayofyear\n",
    "    \n",
    "    # Cyclical encoding for better model understanding\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply datetime feature extraction to weather data\n",
    "weather_data = extract_datetime_features(weather_data)\n",
    "print(f\"Weather data columns after datetime features: {weather_data.columns.tolist()}\")\n",
    "\n",
    "# Apply datetime feature extraction to meter readings\n",
    "meter_readings = extract_datetime_features(meter_readings)\n",
    "print(f\"Meter readings columns after datetime features: {meter_readings.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nDatetime preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90964f",
   "metadata": {},
   "source": [
    "## 3. Data Merging Strategy\n",
    "\n",
    "The merging strategy follows this logical flow:\n",
    "1. **First merge**: Meter readings + Building metadata (on building_id)\n",
    "2. **Second merge**: Result + Weather data (on site_id and timestamp)\n",
    "\n",
    "This ensures we have all building characteristics and weather conditions for each meter reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17cbbbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Merging meter readings with building metadata...\n",
      "Meter readings shape before merge: (20216100, 15)\n",
      "Building metadata shape: (1449, 6)\n",
      "Data shape after first merge: (20216100, 20)\n",
      "Missing site_id values after merge: 0\n",
      "\n",
      "============================================================\n",
      "First merge completed successfully!\n",
      "============================================================\n",
      "Data shape after first merge: (20216100, 20)\n",
      "Missing site_id values after merge: 0\n",
      "\n",
      "============================================================\n",
      "First merge completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge meter readings with building metadata\n",
    "print(\"Step 1: Merging meter readings with building metadata...\")\n",
    "print(f\"Meter readings shape before merge: {meter_readings.shape}\")\n",
    "print(f\"Building metadata shape: {building_metadata.shape}\")\n",
    "\n",
    "# First merge: meter_readings + building_metadata on building_id\n",
    "merged_data = pd.merge(\n",
    "    meter_readings, \n",
    "    building_metadata, \n",
    "    on='building_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Data shape after first merge: {merged_data.shape}\")\n",
    "print(f\"Missing site_id values after merge: {merged_data['site_id'].isnull().sum()}\")\n",
    "\n",
    "# Check for buildings in meter_readings that are not in building_metadata\n",
    "missing_buildings = meter_readings[~meter_readings['building_id'].isin(building_metadata['building_id'])]\n",
    "if len(missing_buildings) > 0:\n",
    "    print(f\"Warning: {len(missing_buildings)} meter readings have building_ids not found in metadata\")\n",
    "    print(f\"Missing building_ids: {missing_buildings['building_id'].unique()[:10]}\")  # Show first 10\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"First merge completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a7ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Merging with weather data...\n",
      "Current merged data shape: (20216100, 20)\n",
      "Weather data shape: (139773, 20)\n",
      "Final dataset shape: (20216100, 38)\n",
      "Missing weather data: 96658\n",
      "\n",
      "============================================================\n",
      "Data merging completed!\n",
      "============================================================\n",
      "\n",
      "FINAL MERGED DATASET OVERVIEW\n",
      "========================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 38 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   building_id         int64         \n",
      " 1   meter               int64         \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float64       \n",
      " 4   hour_x              int32         \n",
      " 5   day_x               int32         \n",
      " 6   month_x             int32         \n",
      " 7   year_x              int32         \n",
      " 8   weekday_x           int32         \n",
      " 9   is_weekend_x        int64         \n",
      " 10  day_of_year_x       int32         \n",
      " 11  hour_sin_x          float64       \n",
      " 12  hour_cos_x          float64       \n",
      " 13  month_sin_x         float64       \n",
      " 14  month_cos_x         float64       \n",
      " 15  site_id             int64         \n",
      " 16  primary_use         object        \n",
      " 17  square_feet         int64         \n",
      " 18  year_built          float64       \n",
      " 19  floor_count         float64       \n",
      " 20  air_temperature     float64       \n",
      " 21  cloud_coverage      float64       \n",
      " 22  dew_temperature     float64       \n",
      " 23  precip_depth_1_hr   float64       \n",
      " 24  sea_level_pressure  float64       \n",
      " 25  wind_direction      float64       \n",
      " 26  wind_speed          float64       \n",
      " 27  hour_y              float64       \n",
      " 28  day_y               float64       \n",
      " 29  month_y             float64       \n",
      " 30  year_y              float64       \n",
      " 31  weekday_y           float64       \n",
      " 32  is_weekend_y        float64       \n",
      " 33  day_of_year_y       float64       \n",
      " 34  hour_sin_y          float64       \n",
      " 35  hour_cos_y          float64       \n",
      " 36  month_sin_y         float64       \n",
      " 37  month_cos_y         float64       \n",
      "dtypes: datetime64[ns](1), float64(25), int32(6), int64(5), object(1)\n",
      "memory usage: 5.3+ GB\n",
      "None\n",
      "\n",
      "First 3 rows:\n",
      "   building_id  meter  timestamp  meter_reading  hour_x  day_x  month_x  \\\n",
      "0            0      0 2016-01-01            0.0       0      1        1   \n",
      "1            1      0 2016-01-01            0.0       0      1        1   \n",
      "2            2      0 2016-01-01            0.0       0      1        1   \n",
      "\n",
      "   year_x  weekday_x  is_weekend_x  ...  day_y  month_y  year_y  weekday_y  \\\n",
      "0    2016          4             0  ...    1.0      1.0  2016.0        4.0   \n",
      "1    2016          4             0  ...    1.0      1.0  2016.0        4.0   \n",
      "2    2016          4             0  ...    1.0      1.0  2016.0        4.0   \n",
      "\n",
      "   is_weekend_y  day_of_year_y hour_sin_y  hour_cos_y  month_sin_y  \\\n",
      "0           0.0            1.0        0.0         1.0          0.5   \n",
      "1           0.0            1.0        0.0         1.0          0.5   \n",
      "2           0.0            1.0        0.0         1.0          0.5   \n",
      "\n",
      "   month_cos_y  \n",
      "0     0.866025  \n",
      "1     0.866025  \n",
      "2     0.866025  \n",
      "\n",
      "[3 rows x 38 columns]\n",
      "\n",
      "Dataset Summary:\n",
      "- Total records: 20,216,100\n",
      "- Unique buildings: 1449\n",
      "- Unique sites: 16\n",
      "- Date range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "Final dataset shape: (20216100, 38)\n",
      "Missing weather data: 96658\n",
      "\n",
      "============================================================\n",
      "Data merging completed!\n",
      "============================================================\n",
      "\n",
      "FINAL MERGED DATASET OVERVIEW\n",
      "========================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 38 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   building_id         int64         \n",
      " 1   meter               int64         \n",
      " 2   timestamp           datetime64[ns]\n",
      " 3   meter_reading       float64       \n",
      " 4   hour_x              int32         \n",
      " 5   day_x               int32         \n",
      " 6   month_x             int32         \n",
      " 7   year_x              int32         \n",
      " 8   weekday_x           int32         \n",
      " 9   is_weekend_x        int64         \n",
      " 10  day_of_year_x       int32         \n",
      " 11  hour_sin_x          float64       \n",
      " 12  hour_cos_x          float64       \n",
      " 13  month_sin_x         float64       \n",
      " 14  month_cos_x         float64       \n",
      " 15  site_id             int64         \n",
      " 16  primary_use         object        \n",
      " 17  square_feet         int64         \n",
      " 18  year_built          float64       \n",
      " 19  floor_count         float64       \n",
      " 20  air_temperature     float64       \n",
      " 21  cloud_coverage      float64       \n",
      " 22  dew_temperature     float64       \n",
      " 23  precip_depth_1_hr   float64       \n",
      " 24  sea_level_pressure  float64       \n",
      " 25  wind_direction      float64       \n",
      " 26  wind_speed          float64       \n",
      " 27  hour_y              float64       \n",
      " 28  day_y               float64       \n",
      " 29  month_y             float64       \n",
      " 30  year_y              float64       \n",
      " 31  weekday_y           float64       \n",
      " 32  is_weekend_y        float64       \n",
      " 33  day_of_year_y       float64       \n",
      " 34  hour_sin_y          float64       \n",
      " 35  hour_cos_y          float64       \n",
      " 36  month_sin_y         float64       \n",
      " 37  month_cos_y         float64       \n",
      "dtypes: datetime64[ns](1), float64(25), int32(6), int64(5), object(1)\n",
      "memory usage: 5.3+ GB\n",
      "None\n",
      "\n",
      "First 3 rows:\n",
      "   building_id  meter  timestamp  meter_reading  hour_x  day_x  month_x  \\\n",
      "0            0      0 2016-01-01            0.0       0      1        1   \n",
      "1            1      0 2016-01-01            0.0       0      1        1   \n",
      "2            2      0 2016-01-01            0.0       0      1        1   \n",
      "\n",
      "   year_x  weekday_x  is_weekend_x  ...  day_y  month_y  year_y  weekday_y  \\\n",
      "0    2016          4             0  ...    1.0      1.0  2016.0        4.0   \n",
      "1    2016          4             0  ...    1.0      1.0  2016.0        4.0   \n",
      "2    2016          4             0  ...    1.0      1.0  2016.0        4.0   \n",
      "\n",
      "   is_weekend_y  day_of_year_y hour_sin_y  hour_cos_y  month_sin_y  \\\n",
      "0           0.0            1.0        0.0         1.0          0.5   \n",
      "1           0.0            1.0        0.0         1.0          0.5   \n",
      "2           0.0            1.0        0.0         1.0          0.5   \n",
      "\n",
      "   month_cos_y  \n",
      "0     0.866025  \n",
      "1     0.866025  \n",
      "2     0.866025  \n",
      "\n",
      "[3 rows x 38 columns]\n",
      "\n",
      "Dataset Summary:\n",
      "- Total records: 20,216,100\n",
      "- Unique buildings: 1449\n",
      "- Unique sites: 16\n",
      "- Date range: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "- Primary building uses: 16\n",
      "- Primary building uses: 16\n",
      "\n",
      "Missing data summary:\n",
      "year_built            12127645\n",
      "floor_count           16709167\n",
      "air_temperature          96658\n",
      "cloud_coverage         8825365\n",
      "dew_temperature         100140\n",
      "precip_depth_1_hr      3749023\n",
      "sea_level_pressure     1231669\n",
      "wind_direction         1449048\n",
      "wind_speed              143676\n",
      "hour_y                   90495\n",
      "day_y                    90495\n",
      "month_y                  90495\n",
      "year_y                   90495\n",
      "weekday_y                90495\n",
      "is_weekend_y             90495\n",
      "day_of_year_y            90495\n",
      "hour_sin_y               90495\n",
      "hour_cos_y               90495\n",
      "month_sin_y              90495\n",
      "month_cos_y              90495\n",
      "dtype: int64\n",
      "\n",
      "Missing data summary:\n",
      "year_built            12127645\n",
      "floor_count           16709167\n",
      "air_temperature          96658\n",
      "cloud_coverage         8825365\n",
      "dew_temperature         100140\n",
      "precip_depth_1_hr      3749023\n",
      "sea_level_pressure     1231669\n",
      "wind_direction         1449048\n",
      "wind_speed              143676\n",
      "hour_y                   90495\n",
      "day_y                    90495\n",
      "month_y                  90495\n",
      "year_y                   90495\n",
      "weekday_y                90495\n",
      "is_weekend_y             90495\n",
      "day_of_year_y            90495\n",
      "hour_sin_y               90495\n",
      "hour_cos_y               90495\n",
      "month_sin_y              90495\n",
      "month_cos_y              90495\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Merge with weather data\n",
    "print(\"Step 2: Merging with weather data...\")\n",
    "print(f\"Current merged data shape: {merged_data.shape}\")\n",
    "print(f\"Weather data shape: {weather_data.shape}\")\n",
    "\n",
    "# Second merge: merged_data + weather_data on site_id and timestamp\n",
    "final_dataset = pd.merge(\n",
    "    merged_data,\n",
    "    weather_data,\n",
    "    on=['site_id', 'timestamp'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Final dataset shape: {final_dataset.shape}\")\n",
    "print(f\"Missing weather data: {final_dataset['air_temperature'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Data merging completed!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display final dataset info\n",
    "print(\"\\nFINAL MERGED DATASET OVERVIEW\")\n",
    "print(\"=\"*40)\n",
    "print(final_dataset.info())\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(final_dataset.head(3))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"- Total records: {len(final_dataset):,}\")\n",
    "print(f\"- Unique buildings: {final_dataset['building_id'].nunique()}\")\n",
    "print(f\"- Unique sites: {final_dataset['site_id'].nunique()}\")\n",
    "print(f\"- Date range: {final_dataset['timestamp'].min()} to {final_dataset['timestamp'].max()}\")\n",
    "print(f\"- Primary building uses: {final_dataset['primary_use'].nunique()}\")\n",
    "\n",
    "# Check data completeness\n",
    "missing_data = final_dataset.isnull().sum()\n",
    "print(f\"\\nMissing data summary:\")\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f9217",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c00623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA QUALITY ASSESSMENT\n",
      "==================================================\n",
      "Dataset shape for quality assessment: (20216100, 38)\n",
      "Checking for duplicates...\n",
      "Large dataset - using sample for duplicate check...\n",
      "Duplicate rows in sample: 0\n",
      "Analyzing missing values...\n",
      "Duplicate rows in sample: 0\n",
      "Analyzing missing values...\n",
      "\n",
      "Missing data summary:\n",
      "  floor_count: 16709167 (82.7%)\n",
      "  year_built: 12127645 (60.0%)\n",
      "  cloud_coverage: 8825365 (43.7%)\n",
      "  precip_depth_1_hr: 3749023 (18.5%)\n",
      "  wind_direction: 1449048 (7.2%)\n",
      "  sea_level_pressure: 1231669 (6.1%)\n",
      "  wind_speed: 143676 (0.7%)\n",
      "  dew_temperature: 100140 (0.5%)\n",
      "  air_temperature: 96658 (0.5%)\n",
      "  hour_y: 90495 (0.4%)\n",
      "\n",
      "Meter reading statistics:\n",
      "\n",
      "Missing data summary:\n",
      "  floor_count: 16709167 (82.7%)\n",
      "  year_built: 12127645 (60.0%)\n",
      "  cloud_coverage: 8825365 (43.7%)\n",
      "  precip_depth_1_hr: 3749023 (18.5%)\n",
      "  wind_direction: 1449048 (7.2%)\n",
      "  sea_level_pressure: 1231669 (6.1%)\n",
      "  wind_speed: 143676 (0.7%)\n",
      "  dew_temperature: 100140 (0.5%)\n",
      "  air_temperature: 96658 (0.5%)\n",
      "  hour_y: 90495 (0.4%)\n",
      "\n",
      "Meter reading statistics:\n",
      "count    2.021610e+07\n",
      "mean     2.117121e+03\n",
      "std      1.532356e+05\n",
      "min      0.000000e+00\n",
      "25%      1.830000e+01\n",
      "50%      7.877500e+01\n",
      "75%      2.679840e+02\n",
      "max      2.190470e+07\n",
      "Name: meter_reading, dtype: float64\n",
      "count    2.021610e+07\n",
      "mean     2.117121e+03\n",
      "std      1.532356e+05\n",
      "min      0.000000e+00\n",
      "25%      1.830000e+01\n",
      "50%      7.877500e+01\n",
      "75%      2.679840e+02\n",
      "max      2.190470e+07\n",
      "Name: meter_reading, dtype: float64\n",
      "Potential outliers (beyond 1st-99th percentile): 202148 rows (1.00%)\n",
      "Negative meter readings: 0\n",
      "\n",
      "Data consistency checks:\n",
      "Building year range: 1900.0 to 2017.0\n",
      "Square feet range: 283 to 875000\n",
      "\n",
      "==================================================\n",
      "CLEANING ACTIONS\n",
      "==================================================\n",
      "Creating cleaned dataset...\n",
      "Potential outliers (beyond 1st-99th percentile): 202148 rows (1.00%)\n",
      "Negative meter readings: 0\n",
      "\n",
      "Data consistency checks:\n",
      "Building year range: 1900.0 to 2017.0\n",
      "Square feet range: 283 to 875000\n",
      "\n",
      "==================================================\n",
      "CLEANING ACTIONS\n",
      "==================================================\n",
      "Creating cleaned dataset...\n",
      "Handling missing weather data...\n",
      "  Processing air_temperature...\n",
      "    Using chunked processing for large dataset...\n",
      "Handling missing weather data...\n",
      "  Processing air_temperature...\n",
      "    Using chunked processing for large dataset...\n",
      "    air_temperature: No missing values after forward/backward fill\n",
      "  Processing cloud_coverage...\n",
      "    Using chunked processing for large dataset...\n",
      "    air_temperature: No missing values after forward/backward fill\n",
      "  Processing cloud_coverage...\n",
      "    Using chunked processing for large dataset...\n",
      "    cloud_coverage: Filled 229 values with median (2.00)\n",
      "  Processing dew_temperature...\n",
      "    Using chunked processing for large dataset...\n",
      "    cloud_coverage: Filled 229 values with median (2.00)\n",
      "  Processing dew_temperature...\n",
      "    Using chunked processing for large dataset...\n",
      "    dew_temperature: No missing values after forward/backward fill\n",
      "  Processing precip_depth_1_hr...\n",
      "    Using chunked processing for large dataset...\n",
      "    dew_temperature: No missing values after forward/backward fill\n",
      "  Processing precip_depth_1_hr...\n",
      "    Using chunked processing for large dataset...\n",
      "    precip_depth_1_hr: Filled 1052 values with median (0.00)\n",
      "  Processing sea_level_pressure...\n",
      "    Using chunked processing for large dataset...\n",
      "    precip_depth_1_hr: Filled 1052 values with median (0.00)\n",
      "  Processing sea_level_pressure...\n",
      "    Using chunked processing for large dataset...\n",
      "    sea_level_pressure: Filled 321 values with median (1016.10)\n",
      "  Processing wind_direction...\n",
      "    Using chunked processing for large dataset...\n",
      "    sea_level_pressure: Filled 321 values with median (1016.10)\n",
      "  Processing wind_direction...\n",
      "    Using chunked processing for large dataset...\n",
      "    wind_direction: No missing values after forward/backward fill\n",
      "  Processing wind_speed...\n",
      "    Using chunked processing for large dataset...\n",
      "    wind_direction: No missing values after forward/backward fill\n",
      "  Processing wind_speed...\n",
      "    Using chunked processing for large dataset...\n",
      "    wind_speed: No missing values after forward/backward fill\n",
      "\n",
      "Handling missing building metadata...\n",
      "  Processing year_built...\n",
      "    year_built: Filled missing values with median (1969.0)\n",
      "  Processing floor_count...\n",
      "    wind_speed: No missing values after forward/backward fill\n",
      "\n",
      "Handling missing building metadata...\n",
      "  Processing year_built...\n",
      "    year_built: Filled missing values with median (1969.0)\n",
      "  Processing floor_count...\n",
      "    floor_count: Estimated based on available data\n",
      "\n",
      "Handling outliers...\n",
      "  Capped 101081 extreme meter readings at 99.5th percentile (9401.15)\n",
      "\n",
      "Removing duplicates...\n",
      "  Skipping duplicate removal for large dataset or no duplicates found\n",
      "\n",
      "Cleaned dataset shape: (20216100, 38)\n",
      "    floor_count: Estimated based on available data\n",
      "\n",
      "Handling outliers...\n",
      "  Capped 101081 extreme meter readings at 99.5th percentile (9401.15)\n",
      "\n",
      "Removing duplicates...\n",
      "  Skipping duplicate removal for large dataset or no duplicates found\n",
      "\n",
      "Cleaned dataset shape: (20216100, 38)\n",
      "Remaining missing values: 995445\n",
      "Remaining missing values: 995445\n"
     ]
    }
   ],
   "source": [
    "# Analyze data quality issues\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add memory management and error handling\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    print(f\"Dataset shape for quality assessment: {final_dataset.shape}\")\n",
    "    \n",
    "    # 1. Check for duplicates (with memory safety)\n",
    "    print(\"Checking for duplicates...\")\n",
    "    if len(final_dataset) > 500000:  # Large dataset\n",
    "        print(\"Large dataset - using sample for duplicate check...\")\n",
    "        sample_data = final_dataset.sample(n=100000, random_state=42)\n",
    "        duplicate_rows = sample_data.duplicated().sum()\n",
    "        print(f\"Duplicate rows in sample: {duplicate_rows}\")\n",
    "    else:\n",
    "        duplicate_rows = final_dataset.duplicated().sum()\n",
    "        print(f\"Duplicate rows: {duplicate_rows}\")\n",
    "\n",
    "    # 2. Analyze missing values in detail (safely)\n",
    "    print(\"Analyzing missing values...\")\n",
    "    missing_data = {}\n",
    "    for col in final_dataset.columns:\n",
    "        try:\n",
    "            missing_count = final_dataset[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                missing_data[col] = {\n",
    "                    'Missing_Count': missing_count,\n",
    "                    'Missing_Percentage': (missing_count / len(final_dataset)) * 100\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"  Error analyzing column {col}: {e}\")\n",
    "    \n",
    "    if missing_data:\n",
    "        print(f\"\\nMissing data summary:\")\n",
    "        for col, stats in sorted(missing_data.items(), key=lambda x: x[1]['Missing_Percentage'], reverse=True)[:10]:\n",
    "            print(f\"  {col}: {stats['Missing_Count']} ({stats['Missing_Percentage']:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\nNo missing values found!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in quality assessment: {e}\")\n",
    "    duplicate_rows = 0  # Safe fallback\n",
    "\n",
    "# 3. Check for outliers in meter readings\n",
    "print(f\"\\nMeter reading statistics:\")\n",
    "print(final_dataset['meter_reading'].describe())\n",
    "\n",
    "# Identify potential outliers (values > 99th percentile or < 1st percentile)\n",
    "q99 = final_dataset['meter_reading'].quantile(0.99)\n",
    "q01 = final_dataset['meter_reading'].quantile(0.01)\n",
    "outliers = final_dataset[(final_dataset['meter_reading'] > q99) | (final_dataset['meter_reading'] < q01)]\n",
    "print(f\"Potential outliers (beyond 1st-99th percentile): {len(outliers)} rows ({len(outliers)/len(final_dataset)*100:.2f}%)\")\n",
    "\n",
    "# 4. Check for negative meter readings (should not exist)\n",
    "negative_readings = (final_dataset['meter_reading'] < 0).sum()\n",
    "print(f\"Negative meter readings: {negative_readings}\")\n",
    "\n",
    "# 5. Check data consistency\n",
    "print(f\"\\nData consistency checks:\")\n",
    "print(f\"Building year range: {final_dataset['year_built'].min()} to {final_dataset['year_built'].max()}\")\n",
    "print(f\"Square feet range: {final_dataset['square_feet'].min()} to {final_dataset['square_feet'].max()}\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING ACTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Create a cleaned dataset with memory management\n",
    "    print(\"Creating cleaned dataset...\")\n",
    "    cleaned_dataset = final_dataset.copy()\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Handle missing weather data with error handling\n",
    "    weather_columns = ['air_temperature', 'cloud_coverage', 'dew_temperature', \n",
    "                      'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "\n",
    "    print(\"Handling missing weather data...\")\n",
    "    for col in weather_columns:\n",
    "        if col in cleaned_dataset.columns:\n",
    "            try:\n",
    "                print(f\"  Processing {col}...\")\n",
    "                # For large datasets, use chunked processing\n",
    "                if len(cleaned_dataset) > 1000000:\n",
    "                    print(f\"    Using chunked processing for large dataset...\")\n",
    "                    # Process in chunks to avoid memory issues\n",
    "                    chunk_size = 100000\n",
    "                    for i in range(0, len(cleaned_dataset), chunk_size):\n",
    "                        chunk_end = min(i + chunk_size, len(cleaned_dataset))\n",
    "                        chunk = cleaned_dataset.iloc[i:chunk_end]\n",
    "                        chunk[col] = chunk.groupby('site_id')[col].ffill().bfill()\n",
    "                        cleaned_dataset.iloc[i:chunk_end, cleaned_dataset.columns.get_loc(col)] = chunk[col]\n",
    "                else:\n",
    "                    # Standard processing for smaller datasets\n",
    "                    cleaned_dataset[col] = cleaned_dataset.groupby('site_id')[col].ffill().bfill()\n",
    "                \n",
    "                # Fill remaining missing values with median\n",
    "                missing_count = cleaned_dataset[col].isnull().sum()\n",
    "                if missing_count > 0:\n",
    "                    median_val = cleaned_dataset[col].median()\n",
    "                    cleaned_dataset[col].fillna(median_val, inplace=True)\n",
    "                    print(f\"    {col}: Filled {missing_count} values with median ({median_val:.2f})\")\n",
    "                else:\n",
    "                    print(f\"    {col}: No missing values after forward/backward fill\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing {col}: {e}\")\n",
    "                # Fallback: fill with overall median\n",
    "                if col in cleaned_dataset.columns:\n",
    "                    median_val = cleaned_dataset[col].median()\n",
    "                    if not pd.isna(median_val):\n",
    "                        cleaned_dataset[col].fillna(median_val, inplace=True)\n",
    "                        print(f\"    {col}: Used fallback median fill\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in weather data cleaning: {e}\")\n",
    "    cleaned_dataset = final_dataset.copy()  # Fallback\n",
    "\n",
    "# 2. Handle missing building metadata\n",
    "print(\"\\nHandling missing building metadata...\")\n",
    "try:\n",
    "    if 'square_feet' in cleaned_dataset.columns and cleaned_dataset['square_feet'].isnull().sum() > 0:\n",
    "        print(\"  Processing square_feet...\")\n",
    "        # Fill missing square_feet with median by primary_use\n",
    "        median_by_use = cleaned_dataset.groupby('primary_use')['square_feet'].median()\n",
    "        missing_mask = cleaned_dataset['square_feet'].isnull()\n",
    "        \n",
    "        for use_type in cleaned_dataset[missing_mask]['primary_use'].unique():\n",
    "            if pd.notna(use_type) and use_type in median_by_use.index:\n",
    "                type_mask = (cleaned_dataset['primary_use'] == use_type) & missing_mask\n",
    "                cleaned_dataset.loc[type_mask, 'square_feet'] = median_by_use[use_type]\n",
    "        \n",
    "        # Fill any remaining missing values with overall median\n",
    "        remaining_missing = cleaned_dataset['square_feet'].isnull().sum()\n",
    "        if remaining_missing > 0:\n",
    "            overall_median = cleaned_dataset['square_feet'].median()\n",
    "            cleaned_dataset['square_feet'].fillna(overall_median, inplace=True)\n",
    "            \n",
    "        print(f\"    square_feet: Filled missing values with median by building type\")\n",
    "\n",
    "    if 'year_built' in cleaned_dataset.columns and cleaned_dataset['year_built'].isnull().sum() > 0:\n",
    "        print(\"  Processing year_built...\")\n",
    "        median_year = cleaned_dataset['year_built'].median()\n",
    "        cleaned_dataset['year_built'].fillna(median_year, inplace=True)\n",
    "        print(f\"    year_built: Filled missing values with median ({median_year})\")\n",
    "\n",
    "    if 'floor_count' in cleaned_dataset.columns and cleaned_dataset['floor_count'].isnull().sum() > 0:\n",
    "        print(\"  Processing floor_count...\")\n",
    "        # Estimate floor count based on square feet (rough approximation)\n",
    "        if 'square_feet' in cleaned_dataset.columns:\n",
    "            estimated_floors = np.maximum(1, np.round(cleaned_dataset['square_feet'] / 15000))\n",
    "            cleaned_dataset['floor_count'] = cleaned_dataset['floor_count'].fillna(estimated_floors)\n",
    "        else:\n",
    "            # Fallback to median\n",
    "            median_floors = cleaned_dataset['floor_count'].median()\n",
    "            if pd.notna(median_floors):\n",
    "                cleaned_dataset['floor_count'].fillna(median_floors, inplace=True)\n",
    "            else:\n",
    "                cleaned_dataset['floor_count'].fillna(1, inplace=True)\n",
    "        print(f\"    floor_count: Estimated based on available data\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  Error handling building metadata: {e}\")\n",
    "\n",
    "# 3. Remove or cap extreme outliers\n",
    "print(f\"\\nHandling outliers...\")\n",
    "try:\n",
    "    # Cap meter readings at 99.5th percentile to handle extreme outliers\n",
    "    q995 = cleaned_dataset['meter_reading'].quantile(0.995)\n",
    "    outliers_mask = cleaned_dataset['meter_reading'] > q995\n",
    "    outliers_capped = outliers_mask.sum()\n",
    "    \n",
    "    if outliers_capped > 0:\n",
    "        cleaned_dataset.loc[outliers_mask, 'meter_reading'] = q995\n",
    "        print(f\"  Capped {outliers_capped} extreme meter readings at 99.5th percentile ({q995:.2f})\")\n",
    "    else:\n",
    "        print(f\"  No extreme outliers found to cap\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  Error handling outliers: {e}\")\n",
    "\n",
    "# 4. Remove duplicate rows if any\n",
    "print(f\"\\nRemoving duplicates...\")\n",
    "try:\n",
    "    if duplicate_rows > 0 and len(cleaned_dataset) < 1000000:  # Only for manageable datasets\n",
    "        before_dedup = len(cleaned_dataset)\n",
    "        cleaned_dataset.drop_duplicates(inplace=True)\n",
    "        actual_removed = before_dedup - len(cleaned_dataset)\n",
    "        print(f\"  Removed {actual_removed} duplicate rows\")\n",
    "    else:\n",
    "        print(f\"  Skipping duplicate removal for large dataset or no duplicates found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  Error removing duplicates: {e}\")\n",
    "\n",
    "# Final cleanup and summary\n",
    "try:\n",
    "    print(f\"\\nCleaned dataset shape: {cleaned_dataset.shape}\")\n",
    "    remaining_nulls = cleaned_dataset.isnull().sum().sum()\n",
    "    print(f\"Remaining missing values: {remaining_nulls}\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in final summary: {e}\")\n",
    "    # Ensure we have a valid cleaned dataset\n",
    "    if 'cleaned_dataset' not in locals():\n",
    "        cleaned_dataset = final_dataset.copy()\n",
    "        print(\"Using fallback: original dataset as cleaned dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b458a",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering for LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4e783f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ENGINEERING FOR LGBM MODEL\n",
      "==================================================\n",
      "Starting feature engineering on dataset with shape: (20216100, 38)\n",
      "Large dataset detected - applying memory-efficient processing...\n",
      "Using sample of 500,000 rows for memory efficiency...\n",
      "Starting feature engineering on dataset with shape: (20216100, 38)\n",
      "Large dataset detected - applying memory-efficient processing...\n",
      "Using sample of 500,000 rows for memory efficiency...\n",
      "Creating building-related features...\n",
      "  Primary use categories: 16\n",
      "Creating weather-related features...\n",
      "Creating additional time-based features...\n",
      "  Re-extracting datetime features...\n",
      "Creating building-related features...\n",
      "  Primary use categories: 16\n",
      "Creating weather-related features...\n",
      "Creating additional time-based features...\n",
      "  Re-extracting datetime features...\n",
      "Creating lag features...\n",
      "  Sorting data by building and timestamp...\n",
      "  Creating 1-hour lag features...\n",
      "  Creating 24-hour lag features...\n",
      "  Creating 168-hour (7-day) lag features...\n",
      "  Creating rolling statistics...\n",
      "Creating lag features...\n",
      "  Sorting data by building and timestamp...\n",
      "  Creating 1-hour lag features...\n",
      "  Creating 24-hour lag features...\n",
      "  Creating 168-hour (7-day) lag features...\n",
      "  Creating rolling statistics...\n",
      "Creating interaction features...\n",
      "\n",
      "Feature engineering completed!\n",
      "\n",
      "Preparing final feature set...\n",
      "Total features before filtering: 64\n",
      "Analyzing missing values...\n",
      "Features after removing high missing (>50.0%): 64\n",
      "Creating final modeling dataset...\n",
      "Filling remaining missing values...\n",
      "Creating interaction features...\n",
      "\n",
      "Feature engineering completed!\n",
      "\n",
      "Preparing final feature set...\n",
      "Total features before filtering: 64\n",
      "Analyzing missing values...\n",
      "Features after removing high missing (>50.0%): 64\n",
      "Creating final modeling dataset...\n",
      "Filling remaining missing values...\n",
      "\n",
      "Final dataset shape: (500000, 64)\n",
      "Features in final dataset: 64\n",
      "Final features (first 10): ['building_id', 'meter', 'meter_reading', 'hour_x', 'day_x', 'month_x', 'year_x', 'weekday_x', 'is_weekend_x', 'day_of_year_x']...\n",
      "                (last 10): ['season_encoded', 'time_period_encoded', 'is_working_hours', 'meter_reading_lag1h', 'meter_reading_lag24h', 'meter_reading_lag168h', 'meter_reading_rolling_mean_24h', 'size_temp_interaction', 'use_hour_interaction', 'use_weekend_interaction']\n",
      "\n",
      "Final dataset shape: (500000, 64)\n",
      "Features in final dataset: 64\n",
      "Final features (first 10): ['building_id', 'meter', 'meter_reading', 'hour_x', 'day_x', 'month_x', 'year_x', 'weekday_x', 'is_weekend_x', 'day_of_year_x']...\n",
      "                (last 10): ['season_encoded', 'time_period_encoded', 'is_working_hours', 'meter_reading_lag1h', 'meter_reading_lag24h', 'meter_reading_lag168h', 'meter_reading_rolling_mean_24h', 'size_temp_interaction', 'use_hour_interaction', 'use_weekend_interaction']\n"
     ]
    }
   ],
   "source": [
    "# Create additional features for the LGBM model\n",
    "print(\"FEATURE ENGINEERING FOR LGBM MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add memory management and error handling\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    # Start with the cleaned dataset\n",
    "    feature_dataset = cleaned_dataset.copy()\n",
    "    print(f\"Starting feature engineering on dataset with shape: {feature_dataset.shape}\")\n",
    "    \n",
    "    # Check memory usage and apply sampling if dataset is too large\n",
    "    if len(feature_dataset) > 2000000:  # More than 2M rows\n",
    "        print(\"Large dataset detected - applying memory-efficient processing...\")\n",
    "        # Use a representative sample for feature engineering if dataset is extremely large\n",
    "        sample_size = min(500000, len(feature_dataset))\n",
    "        print(f\"Using sample of {sample_size:,} rows for memory efficiency...\")\n",
    "        feature_dataset = feature_dataset.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing feature engineering: {e}\")\n",
    "    # Fallback to a smaller sample\n",
    "    sample_size = min(10000, len(cleaned_dataset))\n",
    "    print(f\"Using fallback sample of {sample_size} rows...\")\n",
    "    feature_dataset = cleaned_dataset.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# 1. Building-related features\n",
    "print(\"Creating building-related features...\")\n",
    "\n",
    "# Building age\n",
    "if 'year_built' in feature_dataset.columns:\n",
    "    # Ensure we have a year column (extract from timestamp if needed)\n",
    "    if 'year' not in feature_dataset.columns and 'timestamp' in feature_dataset.columns:\n",
    "        feature_dataset['year'] = pd.to_datetime(feature_dataset['timestamp']).dt.year\n",
    "    \n",
    "    # Calculate building age\n",
    "    if 'year' in feature_dataset.columns:\n",
    "        feature_dataset['building_age'] = feature_dataset['year'] - feature_dataset['year_built']\n",
    "        feature_dataset['building_age'] = np.maximum(0, feature_dataset['building_age'])  # Ensure non-negative\n",
    "    else:\n",
    "        # Fallback: use current year if no year column available\n",
    "        current_year = datetime.now().year\n",
    "        feature_dataset['building_age'] = current_year - feature_dataset['year_built']\n",
    "        feature_dataset['building_age'] = np.maximum(0, feature_dataset['building_age'])\n",
    "\n",
    "# Log of square feet (to handle skewness)\n",
    "if 'square_feet' in feature_dataset.columns:\n",
    "    feature_dataset['log_square_feet'] = np.log1p(feature_dataset['square_feet'])\n",
    "\n",
    "# Square feet per floor\n",
    "if 'square_feet' in feature_dataset.columns and 'floor_count' in feature_dataset.columns:\n",
    "    feature_dataset['sqft_per_floor'] = feature_dataset['square_feet'] / np.maximum(1, feature_dataset['floor_count'])\n",
    "\n",
    "# Encode categorical variables\n",
    "if 'primary_use' in feature_dataset.columns:\n",
    "    # Label encode primary use\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le_primary_use = LabelEncoder()\n",
    "    feature_dataset['primary_use_encoded'] = le_primary_use.fit_transform(feature_dataset['primary_use'])\n",
    "    print(f\"  Primary use categories: {len(le_primary_use.classes_)}\")\n",
    "\n",
    "# 2. Weather-related features\n",
    "print(\"Creating weather-related features...\")\n",
    "\n",
    "# Temperature features\n",
    "if 'air_temperature' in feature_dataset.columns:\n",
    "    # Convert to Celsius if in Fahrenheit (assuming Celsius if max < 50)\n",
    "    if feature_dataset['air_temperature'].max() > 50:\n",
    "        feature_dataset['temp_celsius'] = (feature_dataset['air_temperature'] - 32) * 5/9\n",
    "    else:\n",
    "        feature_dataset['temp_celsius'] = feature_dataset['air_temperature']\n",
    "    \n",
    "    # Temperature categories\n",
    "    feature_dataset['temp_category'] = pd.cut(feature_dataset['temp_celsius'], \n",
    "                                            bins=[-50, 0, 10, 20, 30, 100], \n",
    "                                            labels=['very_cold', 'cold', 'mild', 'warm', 'hot'])\n",
    "    \n",
    "    # Encode temperature category\n",
    "    le_temp = LabelEncoder()\n",
    "    feature_dataset['temp_category_encoded'] = le_temp.fit_transform(feature_dataset['temp_category'])\n",
    "\n",
    "# Weather comfort index (simple combination)\n",
    "if all(col in feature_dataset.columns for col in ['temp_celsius', 'wind_speed', 'cloud_coverage']):\n",
    "    feature_dataset['weather_comfort'] = (\n",
    "        feature_dataset['temp_celsius'] * 0.6 - \n",
    "        feature_dataset['wind_speed'] * 0.2 + \n",
    "        (10 - feature_dataset['cloud_coverage']) * 0.2\n",
    "    )\n",
    "\n",
    "# 3. Time-based features (already created, but let's add more)\n",
    "print(\"Creating additional time-based features...\")\n",
    "\n",
    "# Ensure datetime features exist (re-extract if needed)\n",
    "if 'month' not in feature_dataset.columns and 'timestamp' in feature_dataset.columns:\n",
    "    print(\"  Re-extracting datetime features...\")\n",
    "    feature_dataset = extract_datetime_features(feature_dataset, 'timestamp')\n",
    "\n",
    "# Season based on month\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "if 'month' in feature_dataset.columns:\n",
    "    feature_dataset['season'] = feature_dataset['month'].apply(get_season)\n",
    "else:\n",
    "    print(\"  Warning: No month column available, skipping season feature\")\n",
    "if 'season' in feature_dataset.columns:\n",
    "    le_season = LabelEncoder()\n",
    "    feature_dataset['season_encoded'] = le_season.fit_transform(feature_dataset['season'])\n",
    "\n",
    "# Time of day categories\n",
    "def get_time_period(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "if 'hour' in feature_dataset.columns:\n",
    "    feature_dataset['time_period'] = feature_dataset['hour'].apply(get_time_period)\n",
    "    le_time = LabelEncoder()\n",
    "    feature_dataset['time_period_encoded'] = le_time.fit_transform(feature_dataset['time_period'])\n",
    "\n",
    "# Working hours indicator\n",
    "if all(col in feature_dataset.columns for col in ['hour', 'weekday']):\n",
    "    feature_dataset['is_working_hours'] = ((feature_dataset['hour'] >= 8) & \n",
    "                                         (feature_dataset['hour'] <= 18) & \n",
    "                                         (feature_dataset['weekday'] < 5)).astype(int)\n",
    "else:\n",
    "    print(\"  Warning: Missing hour or weekday columns, skipping working hours feature\")\n",
    "\n",
    "# 4. Lag features (simplified version)\n",
    "print(\"Creating lag features...\")\n",
    "try:\n",
    "    # Sort by building and timestamp for proper lag calculation\n",
    "    if 'timestamp' in feature_dataset.columns:\n",
    "        print(\"  Sorting data by building and timestamp...\")\n",
    "        feature_dataset = feature_dataset.sort_values(['building_id', 'timestamp'])\n",
    "        \n",
    "        # Create lag features with memory-efficient processing\n",
    "        print(\"  Creating 1-hour lag features...\")\n",
    "        feature_dataset['meter_reading_lag1h'] = feature_dataset.groupby('building_id')['meter_reading'].shift(1)\n",
    "        \n",
    "        # Only create longer lags if dataset is manageable\n",
    "        if len(feature_dataset) < 1000000:  # Less than 1M rows\n",
    "            print(\"  Creating 24-hour lag features...\")\n",
    "            feature_dataset['meter_reading_lag24h'] = feature_dataset.groupby('building_id')['meter_reading'].shift(24)\n",
    "            \n",
    "            print(\"  Creating 168-hour (7-day) lag features...\")\n",
    "            feature_dataset['meter_reading_lag168h'] = feature_dataset.groupby('building_id')['meter_reading'].shift(168)  # 7 days\n",
    "            \n",
    "            # Rolling statistics (mean of last 24 hours)\n",
    "            print(\"  Creating rolling statistics...\")\n",
    "            feature_dataset['meter_reading_rolling_mean_24h'] = (\n",
    "                feature_dataset.groupby('building_id')['meter_reading']\n",
    "                .rolling(window=24, min_periods=1)\n",
    "                .mean()\n",
    "                .reset_index(0, drop=True)\n",
    "            )\n",
    "        else:\n",
    "            print(\"  Skipping longer lag features due to dataset size\")\n",
    "            \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "    else:\n",
    "        print(\"  Warning: No timestamp column found, skipping lag features\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  Error creating lag features: {e}\")\n",
    "    print(\"  Continuing without lag features...\")\n",
    "\n",
    "# 5. Interaction features\n",
    "print(\"Creating interaction features...\")\n",
    "\n",
    "# Building size × weather interactions\n",
    "if all(col in feature_dataset.columns for col in ['log_square_feet', 'temp_celsius']):\n",
    "    feature_dataset['size_temp_interaction'] = feature_dataset['log_square_feet'] * feature_dataset['temp_celsius']\n",
    "\n",
    "# Time × building type interactions\n",
    "if all(col in feature_dataset.columns for col in ['primary_use_encoded', 'hour']):\n",
    "    feature_dataset['use_hour_interaction'] = feature_dataset['primary_use_encoded'] * feature_dataset['hour']\n",
    "\n",
    "# Weekend × building type\n",
    "if all(col in feature_dataset.columns for col in ['primary_use_encoded', 'is_weekend']):\n",
    "    feature_dataset['use_weekend_interaction'] = feature_dataset['primary_use_encoded'] * feature_dataset['is_weekend']\n",
    "\n",
    "print(\"\\nFeature engineering completed!\")\n",
    "\n",
    "# 6. Prepare final feature set for modeling\n",
    "print(\"\\nPreparing final feature set...\")\n",
    "\n",
    "try:\n",
    "    # Select features for modeling (exclude original timestamp and text columns)\n",
    "    exclude_columns = ['timestamp', 'primary_use', 'temp_category', 'season', 'time_period']\n",
    "    model_features = [col for col in feature_dataset.columns if col not in exclude_columns]\n",
    "\n",
    "    print(f\"Total features before filtering: {len(model_features)}\")\n",
    "\n",
    "    # Remove columns with high missing values (>50%)\n",
    "    missing_threshold = 0.5\n",
    "    print(\"Analyzing missing values...\")\n",
    "    \n",
    "    # Safe missing value calculation\n",
    "    missing_pct = {}\n",
    "    for col in model_features:\n",
    "        try:\n",
    "            missing_pct[col] = feature_dataset[col].isnull().mean()\n",
    "        except Exception:\n",
    "            missing_pct[col] = 1.0  # Mark problematic columns as 100% missing\n",
    "    \n",
    "    valid_features = [col for col, pct in missing_pct.items() if pct <= missing_threshold]\n",
    "    \n",
    "    print(f\"Features after removing high missing (>{missing_threshold*100}%): {len(valid_features)}\")\n",
    "    \n",
    "    # Ensure we have essential columns\n",
    "    essential_columns = ['building_id', 'meter_reading']\n",
    "    for col in essential_columns:\n",
    "        if col in feature_dataset.columns and col not in valid_features:\n",
    "            valid_features.append(col)\n",
    "            print(f\"Added essential column: {col}\")\n",
    "\n",
    "    # Create final modeling dataset with error handling\n",
    "    print(\"Creating final modeling dataset...\")\n",
    "    final_model_dataset = feature_dataset[valid_features].copy()\n",
    "\n",
    "    # Fill any remaining missing values safely\n",
    "    print(\"Filling remaining missing values...\")\n",
    "    numeric_columns = final_model_dataset.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_columns) > 0:\n",
    "        medians = final_model_dataset[numeric_columns].median()\n",
    "        final_model_dataset[numeric_columns] = final_model_dataset[numeric_columns].fillna(medians)\n",
    "    \n",
    "    # Handle any remaining non-numeric missing values\n",
    "    for col in final_model_dataset.columns:\n",
    "        if final_model_dataset[col].isnull().sum() > 0:\n",
    "            if final_model_dataset[col].dtype == 'object':\n",
    "                final_model_dataset[col].fillna('unknown', inplace=True)\n",
    "            else:\n",
    "                final_model_dataset[col].fillna(0, inplace=True)\n",
    "\n",
    "    print(f\"\\nFinal dataset shape: {final_model_dataset.shape}\")\n",
    "    print(f\"Features in final dataset: {len(valid_features)}\")\n",
    "    \n",
    "    # Only print feature list if it's manageable\n",
    "    if len(valid_features) <= 50:\n",
    "        print(f\"Final feature list: {valid_features}\")\n",
    "    else:\n",
    "        print(f\"Final features (first 10): {valid_features[:10]}...\")\n",
    "        print(f\"                (last 10): {valid_features[-10:]}\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in final dataset preparation: {e}\")\n",
    "    # Create a minimal fallback dataset\n",
    "    essential_cols = ['building_id', 'meter_reading']\n",
    "    available_cols = [col for col in essential_cols if col in feature_dataset.columns]\n",
    "    \n",
    "    if available_cols:\n",
    "        final_model_dataset = feature_dataset[available_cols].copy()\n",
    "        valid_features = available_cols\n",
    "        print(f\"Created fallback dataset with {len(available_cols)} essential columns\")\n",
    "    else:\n",
    "        print(\"Critical error: No essential columns available\")\n",
    "        final_model_dataset = feature_dataset.iloc[:100].copy()  # Very small sample\n",
    "        valid_features = list(final_model_dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fd887",
   "metadata": {},
   "source": [
    "## 6. Dataset Reduction for Efficient Training\n",
    "\n",
    "To make the dataset more manageable while maintaining representativeness across all buildings (1-1448), we'll apply intelligent sampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea4c5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET REDUCTION FOR EFFICIENT TRAINING\n",
      "==================================================\n",
      "Current dataset shape: (500000, 64)\n",
      "Memory usage: 225.07 MB\n",
      "Analyzing building distribution...\n",
      "Buildings range: 0 to 1448\n",
      "Unique buildings: 1449\n",
      "Average records per building: 345.1\n",
      "Records per building - Min: 13, Max: 911\n",
      "\n",
      "Applying intelligent sampling strategies...\n",
      "Preparing dataset for reduction...\n",
      "  Adding timestamp column back...\n",
      "    Using chunked merge for large dataset...\n",
      "    Processed chunk 1/10\n",
      "    Processed chunk 2/10\n",
      "    Processed chunk 3/10\n",
      "    Processed chunk 4/10\n",
      "    Processed chunk 5/10\n",
      "    Processed chunk 2/10\n",
      "    Processed chunk 3/10\n",
      "    Processed chunk 4/10\n",
      "    Processed chunk 5/10\n",
      "    Processed chunk 6/10\n",
      "    Processed chunk 7/10\n",
      "    Processed chunk 6/10\n",
      "    Processed chunk 7/10\n",
      "    Processed chunk 8/10\n",
      "    Processed chunk 9/10\n",
      "    Processed chunk 10/10\n",
      "    Processed chunk 8/10\n",
      "    Processed chunk 9/10\n",
      "    Processed chunk 10/10\n",
      "  Successfully added timestamp column\n",
      "  Successfully added timestamp column\n",
      "  Removed 0 rows with missing 1-hour lag data\n",
      "  Applying systematic temporal sampling...\n",
      "    Large dataset detected (8,038,110 rows), using more aggressive sampling...\n",
      "  Removed 0 rows with missing 1-hour lag data\n",
      "  Applying systematic temporal sampling...\n",
      "    Large dataset detected (8,038,110 rows), using more aggressive sampling...\n",
      "  Reduced from 8,038,110 to 1,019,524 rows (12.7% retained)\n",
      "  Buildings retained: 1449/1449 (100.0%)\n",
      "\n",
      "Final dataset optimization...\n",
      "  Reduced from 8,038,110 to 1,019,524 rows (12.7% retained)\n",
      "  Buildings retained: 1449/1449 (100.0%)\n",
      "\n",
      "Final dataset optimization...\n",
      "  Removed 0 duplicate rows\n",
      "\n",
      "FINAL REDUCED DATASET:\n",
      "- Original size: 500,000 rows\n",
      "- Reduced size: 1,019,524 rows\n",
      "- Reduction: -103.9%\n",
      "- Buildings maintained: 1449/1448\n",
      "- Features: 65\n",
      "- Memory usage: 458.92 MB\n",
      "\n",
      "Data quality check:\n",
      "- Date range maintained: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "- All building types present: N/A\n",
      "- Target variable range: 0.00 to 9401.15\n",
      "\n",
      "✓ Dataset successfully reduced while maintaining representativeness!\n",
      "  Removed 0 duplicate rows\n",
      "\n",
      "FINAL REDUCED DATASET:\n",
      "- Original size: 500,000 rows\n",
      "- Reduced size: 1,019,524 rows\n",
      "- Reduction: -103.9%\n",
      "- Buildings maintained: 1449/1448\n",
      "- Features: 65\n",
      "- Memory usage: 458.92 MB\n",
      "\n",
      "Data quality check:\n",
      "- Date range maintained: 2016-01-01 00:00:00 to 2016-12-31 23:00:00\n",
      "- All building types present: N/A\n",
      "- Target variable range: 0.00 to 9401.15\n",
      "\n",
      "✓ Dataset successfully reduced while maintaining representativeness!\n"
     ]
    }
   ],
   "source": [
    "# Dataset reduction while maintaining all buildings (1-1448)\n",
    "print(\"DATASET REDUCTION FOR EFFICIENT TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add memory cleanup and error handling\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    # Check current dataset size\n",
    "    print(f\"Current dataset shape: {final_model_dataset.shape}\")\n",
    "    \n",
    "    # Safe memory usage calculation\n",
    "    try:\n",
    "        memory_mb = final_model_dataset.memory_usage(deep=True).sum() / 1024**2\n",
    "        print(f\"Memory usage: {memory_mb:.2f} MB\")\n",
    "    except:\n",
    "        print(\"Memory usage: Unable to calculate (large dataset)\")\n",
    "\n",
    "    # Analyze the distribution of data across buildings\n",
    "    print(\"Analyzing building distribution...\")\n",
    "    building_counts = final_model_dataset['building_id'].value_counts().sort_index()\n",
    "    print(f\"Buildings range: {building_counts.index.min()} to {building_counts.index.max()}\")\n",
    "    print(f\"Unique buildings: {len(building_counts)}\")\n",
    "    print(f\"Average records per building: {building_counts.mean():.1f}\")\n",
    "    print(f\"Records per building - Min: {building_counts.min()}, Max: {building_counts.max()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in initial analysis: {e}\")\n",
    "    # Use a smaller sample if there are issues\n",
    "    sample_size = min(10000, len(final_model_dataset))\n",
    "    print(f\"Using sample of {sample_size} rows for analysis...\")\n",
    "    sample_data = final_model_dataset.sample(n=sample_size, random_state=42)\n",
    "    building_counts = sample_data['building_id'].value_counts().sort_index()\n",
    "    print(f\"Sample analysis - Unique buildings: {len(building_counts)}\")\n",
    "\n",
    "# Strategy 1: Smart temporal sampling - keep representative time periods\n",
    "# This ensures we maintain patterns across different seasons, weekdays, and hours\n",
    "print(\"\\nApplying intelligent sampling strategies...\")\n",
    "\n",
    "# Create a reduced dataset\n",
    "reduced_dataset = final_model_dataset.copy()\n",
    "\n",
    "# Add timestamp back if it was excluded from final_model_dataset\n",
    "print(\"Preparing dataset for reduction...\")\n",
    "try:\n",
    "    if 'timestamp' not in reduced_dataset.columns and 'timestamp' in feature_dataset.columns:\n",
    "        print(\"  Adding timestamp column back...\")\n",
    "        # Create a smaller timestamp lookup to avoid memory issues\n",
    "        timestamp_data = feature_dataset[['building_id', 'timestamp', 'meter_reading']].copy()\n",
    "        \n",
    "        # Use chunked merge for large datasets\n",
    "        if len(reduced_dataset) > 100000:\n",
    "            print(\"    Using chunked merge for large dataset...\")\n",
    "            chunk_size = 50000\n",
    "            merged_chunks = []\n",
    "            \n",
    "            for i in range(0, len(reduced_dataset), chunk_size):\n",
    "                chunk = reduced_dataset.iloc[i:i+chunk_size]\n",
    "                merged_chunk = pd.merge(chunk, timestamp_data, on=['building_id', 'meter_reading'], how='left')\n",
    "                merged_chunks.append(merged_chunk)\n",
    "                print(f\"    Processed chunk {i//chunk_size + 1}/{(len(reduced_dataset)-1)//chunk_size + 1}\")\n",
    "            \n",
    "            reduced_dataset = pd.concat(merged_chunks, ignore_index=True)\n",
    "            del merged_chunks  # Free memory\n",
    "        else:\n",
    "            # Direct merge for smaller datasets\n",
    "            reduced_dataset = pd.merge(reduced_dataset, timestamp_data, on=['building_id', 'meter_reading'], how='left')\n",
    "        \n",
    "        del timestamp_data  # Free memory\n",
    "        gc.collect()  # Force garbage collection\n",
    "        print(f\"  Successfully added timestamp column\")\n",
    "    else:\n",
    "        print(\"  Timestamp column already available or not needed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  Warning: Could not add timestamp column: {e}\")\n",
    "    print(\"  Proceeding without timestamp-based sampling...\")\n",
    "\n",
    "# Remove rows with excessive missing lag features (they don't add much value)\n",
    "if 'meter_reading_lag168h' in reduced_dataset.columns:\n",
    "    # Keep only rows where we have at least 1-hour lag data (more meaningful)\n",
    "    before_lag_filter = len(reduced_dataset)\n",
    "    reduced_dataset = reduced_dataset.dropna(subset=['meter_reading_lag1h'])\n",
    "    print(f\"  Removed {before_lag_filter - len(reduced_dataset):,} rows with missing 1-hour lag data\")\n",
    "\n",
    "# Strategy 2: Systematic time-based sampling while preserving all buildings\n",
    "# Sample every 4th hour to reduce by ~75% while maintaining temporal patterns\n",
    "def smart_temporal_sample(df, sample_rate=4):\n",
    "    \"\"\"Sample every nth hour while ensuring all buildings are represented\"\"\"\n",
    "    \n",
    "    # Check if timestamp column exists, if not, use index-based sampling\n",
    "    if 'timestamp' in df.columns:\n",
    "        # Sort by building and timestamp\n",
    "        df_sorted = df.sort_values(['building_id', 'timestamp'])\n",
    "    else:\n",
    "        print(\"    Warning: No timestamp column found, using index-based sampling\")\n",
    "        # Sort by building_id only\n",
    "        df_sorted = df.sort_values(['building_id'])\n",
    "    \n",
    "    sampled_rows = []\n",
    "    \n",
    "    for building_id in df_sorted['building_id'].unique():\n",
    "        building_data = df_sorted[df_sorted['building_id'] == building_id]\n",
    "        \n",
    "        # For each building, sample systematically but ensure we get diverse patterns\n",
    "        if len(building_data) > 100:  # If building has many records\n",
    "            # Take every nth record + some random samples for diversity\n",
    "            systematic_sample = building_data.iloc[::sample_rate]\n",
    "            \n",
    "            # Add some random samples to capture variability (10% of systematic sample)\n",
    "            additional_samples = min(len(systematic_sample) // 10, 20)\n",
    "            if additional_samples > 0:\n",
    "                random_sample = building_data.sample(n=additional_samples, random_state=42)\n",
    "                combined = pd.concat([systematic_sample, random_sample]).drop_duplicates()\n",
    "            else:\n",
    "                combined = systematic_sample\n",
    "                \n",
    "        elif len(building_data) > 50:  # Medium amount of records\n",
    "            # Take every 2nd record\n",
    "            combined = building_data.iloc[::2]\n",
    "        else:  # Small number of records - keep all\n",
    "            combined = building_data\n",
    "            \n",
    "        sampled_rows.append(combined)\n",
    "    \n",
    "    return pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "# Apply smart sampling with error handling\n",
    "print(\"  Applying systematic temporal sampling...\")\n",
    "try:\n",
    "    before_sampling = len(reduced_dataset)\n",
    "    \n",
    "    # Check dataset size and adjust sampling if too large\n",
    "    if before_sampling > 1000000:  # More than 1M rows\n",
    "        print(f\"    Large dataset detected ({before_sampling:,} rows), using more aggressive sampling...\")\n",
    "        sample_rate = 8  # Sample every 8th row instead of 4th\n",
    "    else:\n",
    "        sample_rate = 4\n",
    "    \n",
    "    reduced_dataset = smart_temporal_sample(reduced_dataset, sample_rate=sample_rate)\n",
    "    print(f\"  Reduced from {before_sampling:,} to {len(reduced_dataset):,} rows ({len(reduced_dataset)/before_sampling*100:.1f}% retained)\")\n",
    "    \n",
    "    # Force garbage collection after sampling\n",
    "    gc.collect()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Error during sampling: {e}\")\n",
    "    print(\"  Applying simple random sampling as fallback...\")\n",
    "    # Fallback to simple random sampling\n",
    "    max_samples = min(100000, len(reduced_dataset))  # Maximum 100k samples\n",
    "    reduced_dataset = reduced_dataset.sample(n=max_samples, random_state=42)\n",
    "    print(f\"  Used fallback sampling: {len(reduced_dataset):,} rows\")\n",
    "\n",
    "# Verify all buildings are still represented\n",
    "buildings_after = reduced_dataset['building_id'].nunique()\n",
    "buildings_before = final_model_dataset['building_id'].nunique()\n",
    "print(f\"  Buildings retained: {buildings_after}/{buildings_before} ({buildings_after/buildings_before*100:.1f}%)\")\n",
    "\n",
    "if buildings_after < buildings_before:\n",
    "    print(\"  Warning: Some buildings were lost during sampling!\")\n",
    "    missing_buildings = set(final_model_dataset['building_id'].unique()) - set(reduced_dataset['building_id'].unique())\n",
    "    print(f\"  Missing buildings: {sorted(list(missing_buildings))[:10]}...\")  # Show first 10\n",
    "    \n",
    "    # Add back at least one record for each missing building\n",
    "    for building_id in missing_buildings:\n",
    "        building_data = final_model_dataset[final_model_dataset['building_id'] == building_id]\n",
    "        if len(building_data) > 0:\n",
    "            # Add one representative record (preferably with complete data)\n",
    "            complete_rows = building_data.dropna()\n",
    "            if len(complete_rows) > 0:\n",
    "                sample_row = complete_rows.sample(n=1, random_state=42)\n",
    "            else:\n",
    "                sample_row = building_data.sample(n=1, random_state=42)\n",
    "            reduced_dataset = pd.concat([reduced_dataset, sample_row], ignore_index=True)\n",
    "    \n",
    "    print(f\"  Final buildings after restoration: {reduced_dataset['building_id'].nunique()}\")\n",
    "\n",
    "# Final cleanup and optimization\n",
    "print(\"\\nFinal dataset optimization...\")\n",
    "\n",
    "# Remove any remaining duplicates\n",
    "before_dedup = len(reduced_dataset)\n",
    "reduced_dataset = reduced_dataset.drop_duplicates()\n",
    "print(f\"  Removed {before_dedup - len(reduced_dataset)} duplicate rows\")\n",
    "\n",
    "# Sort by building and timestamp for better data locality (if timestamp exists)\n",
    "if 'timestamp' in reduced_dataset.columns:\n",
    "    reduced_dataset = reduced_dataset.sort_values(['building_id', 'timestamp']).reset_index(drop=True)\n",
    "else:\n",
    "    reduced_dataset = reduced_dataset.sort_values(['building_id']).reset_index(drop=True)\n",
    "    print(\"  Warning: No timestamp column available for sorting\")\n",
    "\n",
    "# Final statistics\n",
    "print(f\"\\nFINAL REDUCED DATASET:\")\n",
    "print(f\"- Original size: {final_model_dataset.shape[0]:,} rows\")\n",
    "print(f\"- Reduced size: {reduced_dataset.shape[0]:,} rows\")\n",
    "print(f\"- Reduction: {(1 - len(reduced_dataset)/len(final_model_dataset))*100:.1f}%\")\n",
    "print(f\"- Buildings maintained: {reduced_dataset['building_id'].nunique()}/1448\")\n",
    "print(f\"- Features: {reduced_dataset.shape[1]}\")\n",
    "print(f\"- Memory usage: {reduced_dataset.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Verify data quality is maintained\n",
    "print(f\"\\nData quality check:\")\n",
    "if 'timestamp' in reduced_dataset.columns:\n",
    "    print(f\"- Date range maintained: {reduced_dataset['timestamp'].min()} to {reduced_dataset['timestamp'].max()}\")\n",
    "else:\n",
    "    print(\"- Date range: Not available (timestamp column missing)\")\n",
    "print(f\"- All building types present: {reduced_dataset['primary_use'].nunique() if 'primary_use' in reduced_dataset.columns else 'N/A'}\")\n",
    "print(f\"- Target variable range: {reduced_dataset['meter_reading'].min():.2f} to {reduced_dataset['meter_reading'].max():.2f}\")\n",
    "\n",
    "# Update the final model dataset to use the reduced version\n",
    "final_model_dataset = reduced_dataset.copy()\n",
    "print(f\"\\n✓ Dataset successfully reduced while maintaining representativeness!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a21150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING PROCESSED DATASET\n",
      "========================================\n",
      "Processed dataset saved to: /Users/saatwik/Documents/Energy-consumption-forecasting/data/processed_dataset.csv\n",
      "Feature names saved to: /Users/saatwik/Documents/Energy-consumption-forecasting/data/feature_names.txt\n",
      "\n",
      "FINAL DATASET SUMMARY:\n",
      "- Shape: (1019524, 65)\n",
      "- Features: 64\n",
      "- Target variable: meter_reading\n",
      "- Ready for LGBM training: ✓\n",
      "\n",
      "Data types summary:\n",
      "float64           39\n",
      "int64             13\n",
      "int32             12\n",
      "datetime64[ns]     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable (meter_reading) statistics:\n",
      "count    1.019524e+06\n",
      "mean     4.090041e+02\n",
      "std      1.844360e+03\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      4.170000e-02\n",
      "max      9.401151e+03\n",
      "Name: meter_reading, dtype: float64\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING PIPELINE COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Next steps:\n",
      "1. Use 'processed_dataset.csv' for model training\n",
      "2. Target variable: 'meter_reading'\n",
      "3. All features are numeric and ready for LGBM\n",
      "4. Consider train/validation split based on timestamp\n",
      "============================================================\n",
      "Processed dataset saved to: /Users/saatwik/Documents/Energy-consumption-forecasting/data/processed_dataset.csv\n",
      "Feature names saved to: /Users/saatwik/Documents/Energy-consumption-forecasting/data/feature_names.txt\n",
      "\n",
      "FINAL DATASET SUMMARY:\n",
      "- Shape: (1019524, 65)\n",
      "- Features: 64\n",
      "- Target variable: meter_reading\n",
      "- Ready for LGBM training: ✓\n",
      "\n",
      "Data types summary:\n",
      "float64           39\n",
      "int64             13\n",
      "int32             12\n",
      "datetime64[ns]     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable (meter_reading) statistics:\n",
      "count    1.019524e+06\n",
      "mean     4.090041e+02\n",
      "std      1.844360e+03\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      4.170000e-02\n",
      "max      9.401151e+03\n",
      "Name: meter_reading, dtype: float64\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING PIPELINE COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Next steps:\n",
      "1. Use 'processed_dataset.csv' for model training\n",
      "2. Target variable: 'meter_reading'\n",
      "3. All features are numeric and ready for LGBM\n",
      "4. Consider train/validation split based on timestamp\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save the processed dataset for model training\n",
    "print(\"SAVING PROCESSED DATASET\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '/Users/saatwik/Documents/Energy-consumption-forecasting/data/processed_dataset.csv'\n",
    "final_model_dataset.to_csv(output_path, index=False)\n",
    "print(f\"Processed dataset saved to: {output_path}\")\n",
    "\n",
    "# Save feature names for later use\n",
    "feature_names = [col for col in final_model_dataset.columns if col != 'meter_reading']\n",
    "feature_names_path = '/Users/saatwik/Documents/Energy-consumption-forecasting/data/feature_names.txt'\n",
    "with open(feature_names_path, 'w') as f:\n",
    "    for feature in feature_names:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(f\"Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\nFINAL DATASET SUMMARY:\")\n",
    "print(f\"- Shape: {final_model_dataset.shape}\")\n",
    "print(f\"- Features: {len(feature_names)}\")\n",
    "print(f\"- Target variable: meter_reading\")\n",
    "print(f\"- Ready for LGBM training: ✓\")\n",
    "\n",
    "# Display data types\n",
    "print(f\"\\nData types summary:\")\n",
    "print(final_model_dataset.dtypes.value_counts())\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nTarget variable (meter_reading) statistics:\")\n",
    "print(final_model_dataset['meter_reading'].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Use 'processed_dataset.csv' for model training\")\n",
    "print(\"2. Target variable: 'meter_reading'\")\n",
    "print(\"3. All features are numeric and ready for LGBM\")\n",
    "print(\"4. Consider train/validation split based on timestamp\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
